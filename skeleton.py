# skeleton.py
import cv2
import numpy as np
import mediapipe as mp
import os
import json
import re
import unicodedata
from tqdm import tqdm
import tempfile

FRAMES_DIR = r"D:\MultiVSL\MultiVSL\dataset\images"
OUTPUT_DIR = r"D:\MultiVSL\MultiVSL\dataset\skeleton"

# T·∫°o output directory
os.makedirs(OUTPUT_DIR, exist_ok=True)

def normalize(s):
    """Chu·∫©n h√≥a Unicode string"""
    return unicodedata.normalize("NFC", s)

def natural_sort(l):
    """S·∫Øp x·∫øp t·ª± nhi√™n"""
    convert = lambda t: int(t) if t.isdigit() else t
    alphanum = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]
    return sorted(l, key=alphanum)

def extract_keypoints(results):
    """Tr√≠ch xu·∫•t 258 keypoints"""
    # Pose
    if results.pose_landmarks:
        pose = np.array([[lm.x, lm.y, lm.z, lm.visibility] 
                         for lm in results.pose_landmarks.landmark]).flatten()
    else:
        pose = np.zeros(33 * 4)

    # Left hand
    if results.left_hand_landmarks:
        lh = np.array([[lm.x, lm.y, lm.z]
                       for lm in results.left_hand_landmarks.landmark]).flatten()
    else:
        lh = np.zeros(21 * 3)

    # Right hand
    if results.right_hand_landmarks:
        rh = np.array([[lm.x, lm.y, lm.z]
                       for lm in results.right_hand_landmarks.landmark]).flatten()
    else:
        rh = np.zeros(21 * 3)

    return np.concatenate([pose, lh, rh]).tolist()

def safe_cv2_imread(image_path):
    """
    ƒê·ªçc ·∫£nh an to√†n v·ªõi ƒë∆∞·ªùng d·∫´n Unicode
    S·ª≠ d·ª•ng temporary file copy n·∫øu c·∫ßn
    """
    try:
        # Th·ª≠ ƒë·ªçc tr·ª±c ti·∫øp
        img = cv2.imread(image_path)
        if img is not None:
            return img
        
        # N·∫øu kh√¥ng ƒë∆∞·ª£c, copy file sang temp path kh√¥ng unicode
        temp_dir = tempfile.gettempdir()
        temp_filename = f"temp_{os.path.basename(image_path)}"
        temp_path = os.path.join(temp_dir, temp_filename)
        
        # Copy file g·ªëc sang temp
        import shutil
        shutil.copy2(image_path, temp_path)
        
        # ƒê·ªçc t·ª´ temp
        img = cv2.imread(temp_path)
        
        # X√≥a temp file
        try:
            os.remove(temp_path)
        except:
            pass
            
        return img
        
    except Exception as e:
        print(f"L·ªói ƒë·ªçc ·∫£nh {image_path}: {e}")
        return None

def extract_skeleton_all():
    """H√†m ch√≠nh tr√≠ch xu·∫•t skeleton v·ªõi fix Unicode"""
    
    print("ü¶¥ B·∫ÆT ƒê·∫¶U TR√çCH XU·∫§T SKELETON...")
    print(f"Input: {FRAMES_DIR}")
    print(f"Output: {OUTPUT_DIR}")
    
    # Kh·ªüi t·∫°o MediaPipe
    mp_holistic = mp.solutions.holistic.Holistic(
        static_image_mode=True,
        model_complexity=1,
        smooth_landmarks=True,
        refine_face_landmarks=False
    )
    
    total_classes = 0
    total_videos = 0
    total_frames = 0
    failed_videos = []
    
    # L·∫•y danh s√°ch class folders
    class_folders = [f for f in os.listdir(FRAMES_DIR) 
                    if os.path.isdir(os.path.join(FRAMES_DIR, f))]
    
    print(f"T·ªïng s·ªë class: {len(class_folders)}")
    
    for label in class_folders:
        label_path = os.path.join(FRAMES_DIR, label)
        label_norm = normalize(label)
        out_label_dir = os.path.join(OUTPUT_DIR, label_norm)
        os.makedirs(out_label_dir, exist_ok=True)

        print(f"\n Class: {label_norm}")
        total_classes += 1
        
        # L·∫•y danh s√°ch video folders
        video_folders = [f for f in os.listdir(label_path) 
                        if os.path.isdir(os.path.join(label_path, f))]
        
        print(f" S·ªë video: {len(video_folders)}")
        
        for video_folder in video_folders:
            video_path = os.path.join(label_path, video_folder)
            video_norm = normalize(video_folder)
            out_video_dir = os.path.join(out_label_dir, video_norm)
            os.makedirs(out_video_dir, exist_ok=True)

            # L·∫•y danh s√°ch frame files
            frame_files = [f for f in os.listdir(video_path) 
                          if f.lower().endswith(".jpg")]
            frame_files = natural_sort(frame_files)
            
            if not frame_files:
                print(f"  {video_norm}: Kh√¥ng c√≥ frames")
                failed_videos.append(f"{label_norm}/{video_norm} - No frames")
                continue
            
            print(f" {video_norm}: {len(frame_files)} frames")
            
            video_frame_count = 0
            video_failed_frames = 0
            
            # X·ª≠ l√Ω t·ª´ng frame
            for frame_file in tqdm(frame_files, desc="      Frames", leave=False):
                frame_path = os.path.join(video_path, frame_file)
                
                try:
                    # ƒê·ªçc ·∫£nh an to√†n
                    img = safe_cv2_imread(frame_path)
                    if img is None:
                        video_failed_frames += 1
                        continue
                    
                    # Resize v√† chuy·ªÉn ƒë·ªïi
                    img = cv2.resize(img, (640, 480))
                    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    
                    # Process v·ªõi MediaPipe
                    results = mp_holistic.process(rgb)
                    keypoints = extract_keypoints(results)
                    
                    # L∆∞u keypoints
                    out_json = os.path.join(out_video_dir, frame_file.replace(".jpg", ".json"))
                    with open(out_json, "w", encoding="utf-8") as f:
                        json.dump(keypoints, f, ensure_ascii=False)
                    
                    video_frame_count += 1
                    total_frames += 1
                    
                except Exception as e:
                    video_failed_frames += 1
                    continue
            
            # Th√¥ng b√°o k·∫øt qu·∫£ video
            if video_frame_count > 0:
                success_rate = (video_frame_count / len(frame_files)) * 100
                print(f" {video_norm}: {video_frame_count}/{len(frame_files)} frames ({success_rate:.1f}%)")
                total_videos += 1
                
                if video_failed_frames > 0:
                    print(f" {video_failed_frames} frames th·∫•t b·∫°i")
            else:
                print(f" {video_norm}: TH·∫§T B·∫†I")
                failed_videos.append(f"{label_norm}/{video_norm}")
    
    # ƒê√≥ng MediaPipe
    mp_holistic.close()
    
    # Summary
    print(f"\n HO√ÄN TH√ÄNH TR√çCH XU·∫§T SKELETON")
    print(f"  S·ªë class: {total_classes}")
    print(f"  S·ªë video th√†nh c√¥ng: {total_videos}")
    print(f"  S·ªë frames: {total_frames}")
    
    if failed_videos:
        print(f"\n Video th·∫•t b·∫°i ({len(failed_videos)}):")
        for failed in failed_videos[:10]:  # Hi·ªÉn th·ªã 10 c√°i ƒë·∫ßu
            print(f"   - {failed}")
        if len(failed_videos) > 10:
            print(f"   ... v√† {len(failed_videos) - 10} video kh√°c")

def rename_unicode_folders():
    """
    ƒê·ªïi t√™n folders c√≥ k√Ω t·ª± Unicode sang kh√¥ng d·∫•u
    Ch·ªâ ch·∫°y n·∫øu c·∫ßn thi·∫øt
    """
    FRAMES_DIR = r"D:\MultiVSL\MultiVSL\dataset\images"
    
    print(" ƒêang ƒë·ªïi t√™n folders Unicode...")
    
    # Map c√°c k√Ω t·ª± Unicode sang kh√¥ng d·∫•u
    unicode_map = {
        '√°': 'a', '√†': 'a', '·∫£': 'a', '√£': 'a', '·∫°': 'a',
        'ƒÉ': 'a', '·∫Ø': 'a', '·∫±': 'a', '·∫≥': 'a', '·∫µ': 'a', '·∫∑': 'a',
        '√¢': 'a', '·∫•': 'a', '·∫ß': 'a', '·∫©': 'a', '·∫´': 'a', '·∫≠': 'a',
        'ƒë': 'd',
        '√©': 'e', '√®': 'e', '·∫ª': 'e', '·∫Ω': 'e', '·∫π': 'e',
        '√™': 'e', '·∫ø': 'e', '·ªÅ': 'e', '·ªÉ': 'e', '·ªÖ': 'e', '·ªá': 'e',
        '√≠': 'i', '√¨': 'i', '·ªâ': 'i', 'ƒ©': 'i', '·ªã': 'i',
        '√≥': 'o', '√≤': 'o', '·ªè': 'o', '√µ': 'o', '·ªç': 'o',
        '√¥': 'o', '·ªë': 'o', '·ªì': 'o', '·ªï': 'o', '·ªó': 'o', '·ªô': 'o',
        '∆°': 'o', '·ªõ': 'o', '·ªù': 'o', '·ªü': 'o', '·ª°': 'o', '·ª£': 'o',
        '√∫': 'u', '√π': 'u', '·ªß': 'u', '≈©': 'u', '·ª•': 'u',
        '∆∞': 'u', '·ª©': 'u', '·ª´': 'u', '·ª≠': 'u', '·ªØ': 'u', '·ª±': 'u',
        '√Ω': 'y', '·ª≥': 'y', '·ª∑': 'y', '·ªπ': 'y', '·ªµ': 'y',
        ' ': '_'
    }
    
    def remove_accents(text):
        for char, replacement in unicode_map.items():
            text = text.replace(char, replacement)
            text = text.replace(char.upper(), replacement.upper())
        return text
    
    renamed_count = 0
    
    for root, dirs, files in os.walk(FRAMES_DIR):
        for name in list(dirs):
            old_path = os.path.join(root, name)
            new_name = remove_accents(name)
            
            if new_name != name:
                new_path = os.path.join(root, new_name)
                try:
                    os.rename(old_path, new_path)
                    print(f"‚úÖ ƒê√£ ƒë·ªïi: {name} -> {new_name}")
                    renamed_count += 1
                except Exception as e:
                    print(f" L·ªói ƒë·ªïi {name}: {e}")
    
    print(f" ƒê√£ ƒë·ªïi {renamed_count} folders")

if __name__ == "__main__":
    print(">>> Script started")
    print(">>> Loading MediaPipe...")
    
    # Option 1: ƒê·ªïi t√™n folders tr∆∞·ªõc (n·∫øu c·∫ßn)
    # rename_unicode_folders()
    
    # Option 2: Ch·∫°y tr√≠ch xu·∫•t v·ªõi fix Unicode
    extract_skeleton_all()