import numpy as np
import os
from tqdm import tqdm
from collections import Counter
import math

# ================== CONFIG ==================
OUTPUT_DIR = r"D:\MultiVSL\MultiVSL\dataset\stgcn_dataset"
TARGET_SAMPLES_PER_CLASS = 100  # M·ª•c ti√™u: M·ªói t·ª´ s·∫Ω c√≥ 100 m·∫´u (bao g·ªìm c·∫£ g·ªëc)
TARGET_FRAMES = 64
NOISE_STD = 0.01
SCALE_RANGE = (0.95, 1.05)
TRANSLATE_RANGE = 0.05

# ================== AUGMENT FUNCTION ==================
def augment_keypoints(sequence, target_frames=64, noise_std=0.01, scale_range=(0.95,1.05), translate_range=0.05):
    """
    Augment 1 sequence keypoints VSL (T, V, 3) - Gi·ªØ nguy√™n h√†m n√†y
    """
    seq = sequence.copy()
    T, V, C = seq.shape
    
    # Temporal sampling
    if T != target_frames:
        indices = np.linspace(0, T - 1, target_frames).astype(int)
        seq = seq[indices]
    
    # Gaussian noise
    seq += np.random.normal(0, noise_std, seq.shape)
    
    # Scale x, y
    scale_x = np.random.uniform(scale_range[0], scale_range[1])
    scale_y = np.random.uniform(scale_range[0], scale_range[1])
    seq[..., 0] *= scale_x
    seq[..., 1] *= scale_y
    
    # Translate x, y
    trans_x = np.random.uniform(-translate_range, translate_range)
    trans_y = np.random.uniform(-translate_range, translate_range)
    seq[..., 0] += trans_x
    seq[..., 1] += trans_y
    
    # Center pelvis (joint 0)
    center = seq[:, 0:1, :]
    seq = seq - center
    
    return seq

# ================== BALANCED AUGMENT DATASET ==================
def augment_dataset_balanced(data_path, labels_path, target_count=TARGET_SAMPLES_PER_CLASS):
    """
    T·∫°o dataset c√¢n b·∫±ng: M·ªói class s·∫Ω ƒë∆∞·ª£c augment cho ƒë·∫øn khi ƒë·∫°t ƒë·ªß target_count
    """
    print("üîÑ ƒêang load d·ªØ li·ªáu g·ªëc...")
    data = np.load(data_path)   # (N, C, T, V, M)
    labels = np.load(labels_path)
    
    N, C, T, V, M = data.shape
    
    # 1. Ph√¢n nh√≥m d·ªØ li·ªáu theo Class (Label)
    class_data_map = {} # {label: [index1, index2, ...]}
    for idx, label in enumerate(labels):
        if label not in class_data_map:
            class_data_map[label] = []
        class_data_map[label].append(idx)
        
    augmented_data = []
    augmented_labels = []
    
    print(f"M·ª•c ti√™u: {target_count} m·∫´u/class")
    print(f"Th·ªëng k√™ tr∆∞·ªõc khi Augment: {dict(Counter(labels))}")

    # 2. Duy·ªát qua t·ª´ng Class ƒë·ªÉ x·ª≠ l√Ω
    sorted_labels = sorted(class_data_map.keys())
    
    for label in tqdm(sorted_labels, desc="Balancing Classes"):
        indices = class_data_map[label]
        current_count = len(indices)
        
        # L·∫•y d·ªØ li·ªáu g·ªëc c·ªßa class n√†y
        class_samples = []
        for idx in indices:
            # Chuy·ªÉn v·ªÅ (T, V, C) ƒë·ªÉ d·ªÖ augment
            seq = data[idx].squeeze(-1).transpose(1, 2, 0)
            class_samples.append(seq)
            
            # Th√™m lu√¥n b·∫£n g·ªëc v√†o danh s√°ch k·∫øt qu·∫£
            augmented_data.append(data[idx])
            augmented_labels.append(label)
            
        # T√≠nh to√°n s·ªë l∆∞·ª£ng c·∫ßn sinh th√™m
        needed = target_count - current_count
        
        if needed <= 0:
            # N·∫øu class n√†y ƒë√£ c√≥ ƒë·ªß ho·∫∑c th·ª´a m·∫´u th√¨ th√¥i (ho·∫∑c c√≥ th·ªÉ c·∫Øt b·ªõt n·∫øu mu·ªën)
            continue
            
        # Sinh th√™m d·ªØ li·ªáu
        # ƒê·ªÉ sinh ƒë·ªß 'needed' m·∫´u t·ª´ 'current_count' video g·ªëc, ta chia ƒë·ªÅu
        generated_count = 0
        i = 0
        
        while generated_count < needed:
            # L·∫•y video g·ªëc theo v√≤ng tr√≤n (Round-robin) ƒë·ªÉ augment ƒë·ªÅu c√°c m·∫´u g·ªëc
            original_seq = class_samples[i % current_count]
            
            aug_seq = augment_keypoints(original_seq, target_frames=T, 
                                        noise_std=NOISE_STD,
                                        scale_range=SCALE_RANGE,
                                        translate_range=TRANSLATE_RANGE)
            
            # Chuy·ªÉn v·ªÅ l·∫°i format ST-GCN (C, T, V, M)
            aug_seq_stgcn = aug_seq.transpose(2, 0, 1)[..., np.newaxis]
            
            augmented_data.append(aug_seq_stgcn)
            augmented_labels.append(label)
            
            generated_count += 1
            i += 1

    # Convert th√†nh np.array
    augmented_data = np.array(augmented_data)
    augmented_labels = np.array(augmented_labels)
    
    # L∆∞u ra file
    np.save(os.path.join(OUTPUT_DIR, 'stgcn_data_aug.npy'), augmented_data)
    np.save(os.path.join(OUTPUT_DIR, 'stgcn_labels_aug.npy'), augmented_labels)
    
    print(f"\n‚úÖ Dataset augmented saved successfully!")
    print(f"Original samples: {N}")
    print(f"Total samples after balancing: {len(augmented_data)}")
    
    # Ki·ªÉm tra l·∫°i ƒë·ªô c√¢n b·∫±ng
    print(f"üìä Th·ªëng k√™ sau khi Augment (Sample): {dict(list(Counter(augmented_labels).items())[:5])} ...")

# ================== RUN ==================
if __name__ == "__main__":
    data_path = os.path.join(OUTPUT_DIR, 'stgcn_data.npy')
    labels_path = os.path.join(OUTPUT_DIR, 'stgcn_labels.npy')
    
    # Ch·∫°y h√†m c√¢n b·∫±ng thay v√¨ h√†m c≈©
    augment_dataset_balanced(data_path, labels_path, target_count=100)